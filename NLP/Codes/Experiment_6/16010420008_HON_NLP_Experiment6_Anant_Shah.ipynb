{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importing necessary libraries**"
      ],
      "metadata": {
        "id": "OngSMyjblEFZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-4lwY2rjYNy",
        "outputId": "653da270-d05c-46c4-bfc2-73aaa2e004b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import word_tokenize\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the file and saving in answer_column array**"
      ],
      "metadata": {
        "id": "Z21vFZIjnHr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file = pd.read_csv('/content/Answers.csv')\n",
        "csv_file_column = csv_file[csv_file['Body'].notna()]\n",
        "\n",
        "answer_column = []\n",
        "for i in range(10, 11):\n",
        "    answer_column.append(csv_file_column['Body'][i])"
      ],
      "metadata": {
        "id": "miDgV8RdnIRQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HTML Removal Function**"
      ],
      "metadata": {
        "id": "zVXxljiaxMaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def html_removal(text):\n",
        "    pattern = r\"<[^>]+>\"\n",
        "    html_removal_text = re.sub(pattern, \"\", text)\n",
        "    return html_removal_text"
      ],
      "metadata": {
        "id": "nTNrvb7ixMti"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemmatize without POS tagging Function**"
      ],
      "metadata": {
        "id": "_-vUFlM8r0M0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def without_pos_tagging(lemmatizer, tokenized_words):\n",
        "  lemmatized_words_without_pos = [lemmatizer.lemmatize(word) for word in tokenized_words]\n",
        "  return lemmatized_words_without_pos"
      ],
      "metadata": {
        "id": "BVMnjUwTrzz_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemmatize with POS tagging Function**"
      ],
      "metadata": {
        "id": "kSSY6xslrig1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def with_pos_tagging(treebank_tag):\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN"
      ],
      "metadata": {
        "id": "qM8WKkGnriBU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calling the functions**"
      ],
      "metadata": {
        "id": "xPAgwQr-vFZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in answer_column:\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    html_removal_text = html_removal(i)\n",
        "    print(f\"The original text is: {html_removal_text}.\")\n",
        "    tokenized_words = word_tokenize(html_removal_text)\n",
        "    without_pos_tagging = without_pos_tagging(lemmatizer, tokenized_words)\n",
        "    print(f\"The text without pos tagging is: {without_pos_tagging}.\")\n",
        "    pos_tags = nltk.pos_tag(tokenized_words)\n",
        "    lemmatized_words_with_pos = [lemmatizer.lemmatize(word, with_pos_tagging(tag)) for word, tag in pos_tags]\n",
        "    print(f\"The text with pos tagging is: {without_pos_tagging}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OWwMNnRvFm6",
        "outputId": "8c3694af-d8eb-4cb2-b28e-088bcdcf2913"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original text is: For my projects I alternate between SQL Compare from REd Gate and the Database Publishing Wizard from Microsoft which you can download free\r\n",
            "here.\r\n",
            "\r\n",
            "The Wizard isn't as slick as SQL Compare or SQL Data Compare but it does the trick. One issue is that the scripts it generates may need some rearranging and/or editing to flow in one shot.\r\n",
            "\r\n",
            "On the up side, it can move your schema and data which isn't bad for a free tool..\n",
            "The text without pos tagging is: ['For', 'my', 'project', 'I', 'alternate', 'between', 'SQL', 'Compare', 'from', 'REd', 'Gate', 'and', 'the', 'Database', 'Publishing', 'Wizard', 'from', 'Microsoft', 'which', 'you', 'can', 'download', 'free', 'here', '.', 'The', 'Wizard', 'is', \"n't\", 'a', 'slick', 'a', 'SQL', 'Compare', 'or', 'SQL', 'Data', 'Compare', 'but', 'it', 'doe', 'the', 'trick', '.', 'One', 'issue', 'is', 'that', 'the', 'script', 'it', 'generates', 'may', 'need', 'some', 'rearranging', 'and/or', 'editing', 'to', 'flow', 'in', 'one', 'shot', '.', 'On', 'the', 'up', 'side', ',', 'it', 'can', 'move', 'your', 'schema', 'and', 'data', 'which', 'is', \"n't\", 'bad', 'for', 'a', 'free', 'tool', '.'].\n",
            "The text with pos tagging is: ['For', 'my', 'project', 'I', 'alternate', 'between', 'SQL', 'Compare', 'from', 'REd', 'Gate', 'and', 'the', 'Database', 'Publishing', 'Wizard', 'from', 'Microsoft', 'which', 'you', 'can', 'download', 'free', 'here', '.', 'The', 'Wizard', 'be', \"n't\", 'as', 'slick', 'a', 'SQL', 'Compare', 'or', 'SQL', 'Data', 'Compare', 'but', 'it', 'do', 'the', 'trick', '.', 'One', 'issue', 'be', 'that', 'the', 'script', 'it', 'generate', 'may', 'need', 'some', 'rearrange', 'and/or', 'edit', 'to', 'flow', 'in', 'one', 'shot', '.', 'On', 'the', 'up', 'side', ',', 'it', 'can', 'move', 'your', 'schema', 'and', 'data', 'which', 'be', \"n't\", 'bad', 'for', 'a', 'free', 'tool', '.'].\n"
          ]
        }
      ]
    }
  ]
}