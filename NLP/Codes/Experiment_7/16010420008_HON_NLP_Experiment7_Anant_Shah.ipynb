{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importing necessary libraries and loading necessary models**"
      ],
      "metadata": {
        "id": "UhxtGhNBxnhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "spacy_model = spacy.load(\"en_core_web_sm\")\n",
        "from nltk.chunk.regexp import RegexpParser\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVdQLkLnx3A6",
        "outputId": "38fe3c9c-a6fa-4712-8838-1350d78c2314"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the file and saving in answer_column array**"
      ],
      "metadata": {
        "id": "x83Y4iiwx2Mz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ahWTqsxXxc3b"
      },
      "outputs": [],
      "source": [
        "csv_file = pd.read_csv('/content/Answers.csv')\n",
        "csv_file_column = csv_file[csv_file['Body'].notna()]\n",
        "\n",
        "answer_column = []\n",
        "for i in range(0, 1):\n",
        "    answer_column.append(csv_file_column['Body'][i])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HTML Removal Function**"
      ],
      "metadata": {
        "id": "0jvQ0cTNyCd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def html_removal(text):\n",
        "    pattern = r\"<[^>]+>\"\n",
        "    html_removal_text = re.sub(pattern, \"\", text)\n",
        "    return html_removal_text"
      ],
      "metadata": {
        "id": "zdryUsxVyCyx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dependency Parser Function**\n"
      ],
      "metadata": {
        "id": "Fb15VVNLybK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dependency_parser(text):\n",
        "    parsed_text = spacy_model(text)\n",
        "    return parsed_text"
      ],
      "metadata": {
        "id": "YfXxXAedyrJp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regexp Parser Function**"
      ],
      "metadata": {
        "id": "T9-1K6IfzqPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def regexp_parser(text):\n",
        "    grammar = r\"\"\"\n",
        "      NP: {<DT|JJ|NN.*>+}\n",
        "      PP: {<IN><NP>}\n",
        "      VP: {<VB.*><NP|PP|CLAUSE>+$}\n",
        "      CLAUSE: {<NP><VP>}\n",
        "    \"\"\"\n",
        "\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "    parser = RegexpParser(grammar)\n",
        "\n",
        "    parsed_text = parser.parse(tagged)\n",
        "    parsed_text = parsed_text.__str__()\n",
        "    return parsed_text"
      ],
      "metadata": {
        "id": "omWnuJt8zqpl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calling the functions**"
      ],
      "metadata": {
        "id": "L7z7AU4r1fBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in answer_column:\n",
        "    html_removal_text = html_removal(i)\n",
        "    print(f\"The original text is: {html_removal_text}.\")\n",
        "    dependency_parser = dependency_parser(html_removal_text)\n",
        "    print(f\"The parsed text using dependency parser is:  \")\n",
        "    for token in dependency_parser:\n",
        "        print(f\"{token.text} ({token.dep_} -> {token.head.text})\")\n",
        "    regexp_parser = regexp_parser(html_removal_text)\n",
        "    print(f\"\\nThe parsed text using regexp parser is: {regexp_parser}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PRYmWbW1fSB",
        "outputId": "9e45f345-f988-4fc7-a89b-a08bd7c63576"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original text is: Version Control with Subversion\r\n",
            "\r\n",
            "A very good resource for source control in general. Not really TortoiseSVN specific, though..\n",
            "The parsed text using dependency parser is:  \n",
            "Version (compound -> Control)\n",
            "Control (ROOT -> Control)\n",
            "with (prep -> Control)\n",
            "Subversion (pobj -> with)\n",
            "\r\n",
            "\r\n",
            " (dep -> Subversion)\n",
            "A (det -> resource)\n",
            "very (advmod -> good)\n",
            "good (amod -> resource)\n",
            "resource (ROOT -> resource)\n",
            "for (prep -> resource)\n",
            "source (compound -> control)\n",
            "control (pobj -> for)\n",
            "in (prep -> control)\n",
            "general (amod -> in)\n",
            ". (punct -> resource)\n",
            "Not (neg -> TortoiseSVN)\n",
            "really (advmod -> TortoiseSVN)\n",
            "TortoiseSVN (ROOT -> TortoiseSVN)\n",
            "specific (acomp -> TortoiseSVN)\n",
            ", (punct -> TortoiseSVN)\n",
            "though (advmod -> TortoiseSVN)\n",
            ". (punct -> TortoiseSVN)\n",
            "\n",
            "The parsed text using regexp parser is: (S\n",
            "  (NP Version/NNP Control/NNP)\n",
            "  (PP with/IN (NP Subversion/NNP A/NNP))\n",
            "  very/RB\n",
            "  (NP good/JJ resource/NN)\n",
            "  (PP for/IN (NP source/NN control/NN))\n",
            "  (PP in/IN (NP general/JJ))\n",
            "  ./.\n",
            "  Not/RB\n",
            "  really/RB\n",
            "  (NP TortoiseSVN/NNP specific/NN)\n",
            "  ,/,\n",
            "  though/RB\n",
            "  ./.)\n"
          ]
        }
      ]
    }
  ]
}